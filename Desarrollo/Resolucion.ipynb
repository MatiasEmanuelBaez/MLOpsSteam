{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "### TRABAJAMOS SOBRE EL ARCHIVO DE JUEGOS ###\n",
    "#############################################\n",
    "\n",
    "datos = []            # Definimos/limpiamos una lista que servira como nexo entre los datos y el dataframe.\n",
    "with open('output_steam_games.json') as archivo:            # Abrimos el archivo json.\n",
    "    for linea in archivo:\n",
    "        datos.append(json.loads(linea))         # Agregamos cada linea del json a la lista ya creada.\n",
    "\n",
    "dfGames = pd.DataFrame(datos)          # Creamos un dataframe con los datos de la lista.\n",
    "dfGames = dfGames.dropna(axis=0, how='all')           # Eliminamos del dataframe las filas en las que todos sus campos son nulos.\n",
    "\n",
    "dfGames = dfGames.drop(['publisher', 'title', 'url', 'specs', 'price', 'reviews_url', 'price', 'early_access', 'developer'], axis=1)          # Eliminamos las columnos que no seran de ayuda en el analisis.\n",
    "\n",
    "dfGames = dfGames.dropna(subset=['release_date'])        # Eliminanos los datos nan de la columna de fechas.\n",
    "\n",
    "for fila in dfGames['release_date']:\n",
    "    try:\n",
    "        dfGames.loc[dfGames['release_date'] == fila, 'nueva_fecha'] = datetime.strptime(fila, \"%Y-%m-%d\").year         # Guardamos en una nueva columna, las fechas con formato valido.\n",
    "    except ValueError:\n",
    "       dfGames.loc[dfGames['release_date'] == fila, 'nueva_fecha'] = None         # Si la fecha no es valida, guardamos un nan en su lugar.\n",
    "       \n",
    "\n",
    "dfGames = dfGames.drop(['release_date'], axis = 1)            # Eliminamos la columna que ya no sera de ayuda.\n",
    "dfGames = dfGames.rename(columns = {'nueva_fecha': 'release_date'})         # Renombramos la nueva columna con el nombre que ya nos hemos familiarizado.\n",
    "dfGames = dfGames.dropna(subset = ['release_date'])        #Eliminanos los datos nan de la columna de fechas.\n",
    "dfGames = dfGames.explode('genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "### TRABAJAMOS SOBRE EL ARCHIVO DE REVIEWS ###\n",
    "##############################################\n",
    "\n",
    "datos=[]            # Definimos/limpiamos una lista que servira como nexo entre los datos y el dataframe.\n",
    "\n",
    "with open('australian_user_reviews.json') as archivo:           # Abrimos el archivo json.\n",
    "    for lineas in archivo:\n",
    "        linea = ast.literal_eval(lineas)            # Ayuda a manejar el \"json\" sin que el formato traiga problemas.\n",
    "        datos.append(linea)         # Agregamos cada linea del \"json\" a la lista ya creada.\n",
    "\n",
    "dfReviews = pd.DataFrame(datos)         # Creamos un dataframe con los datos de la lista.\n",
    "dfReviews = dfReviews.drop(['user_url'], axis = 1)            # Eliminamos las columnos que no seran de ayuda en el analisis.\n",
    "\n",
    "\n",
    "dfReviews = dfReviews.drop_duplicates('user_id')            # Eliminamos los usuarios que esten duplicados.\n",
    "dfReviews = dfReviews.explode('reviews')          # Se desanidan los reviews, trasladando cada una a una fila diferente.\n",
    "\n",
    "dfReviews.dropna()          # Eliminamos los registros nan.\n",
    "dfReviews = dfReviews.dropna(subset = ['reviews'])            # Eliminamos las filas que no tengan reviews.\n",
    "\n",
    "for key in dfReviews['reviews'].iloc[0].keys():         \n",
    "    dfReviews[key] = dfReviews['reviews'].apply(lambda x: x[key])         # Toma cada \"llave/valor\" correspondiente a las reviews y arma columnas aparte para tener los datos ordenados y accesibles.\n",
    "    \n",
    "dfReviews = dfReviews.drop(['reviews', 'funny', 'last_edited', 'helpful'], axis = 1)         # Eliminamos la columna REVIEWS, la cual ya fue desanidada y otras que no utilizaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "### TRABAJAMOS SOBRE EL ARCHIVO DE ITEMS ###\n",
    "############################################\n",
    "\n",
    "datos=[]            # Definimos/limpiamos una lista que servira como nexo entre los datos y el dataframe.\n",
    "\n",
    "with open('australian_users_items.json') as archivo:            # Abrimos el archivo json.\n",
    "    for lineas in archivo:\n",
    "        linea = ast.literal_eval(lineas)         # Ayuda a manejar el \"json\" sin que el formato traiga problemas.\n",
    "        datos.append(linea)         # Agregamos cada linea del \"json\" a la lista ya creada.\n",
    "\n",
    "dfItems = pd.DataFrame(datos)         # Creamos un dataframe con los datos de la lista.\n",
    "dfItems = dfItems.drop(['user_url', 'steam_id'], axis=1)            # Eliminamos las columnos que no seran de ayuda en el analisis.\n",
    "\n",
    "\n",
    "dfItems = dfItems.drop_duplicates('user_id')            # Eliminamos los usuarios que esten duplicados.\n",
    "dfItems = dfItems.drop(dfItems[(dfItems['items_count'] == 0)].index)            # Eliminamos los usuarios que no tengan juegos.\n",
    "dfItems = dfItems.explode('items')          # Se desanidan los juegos, trasladando cada uno a una fila diferente.\n",
    "\n",
    "for key in dfItems['items'].iloc[0].keys():         \n",
    "    dfItems[key] = dfItems['items'].apply(lambda x: x[key])         # Toma cada \"llave/valor\" correspondiente a los juegos y arma columnas aparte para tener los datos ordenados y accesibles.\n",
    "    \n",
    "dfItems = dfItems.drop(['items', 'items_count', 'playtime_2weeks'], axis = 1)         # Eliminamos la columna ITEMS, la cual ya fue desanidada y otras que no utilizaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfItems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### PRIMER CONSULTA ###\n",
    "#######################\n",
    "\n",
    "dfAux = dfItems.groupby(by = 'item_id').playtime_forever.sum()            # Agrupamos los juegos, obteniendo las horas totales de juego.\n",
    "dfResultadoU = pd.merge(dfGames, dfAux, how = 'inner', left_on='id', right_on = 'item_id')         # Agregamos al dataframe JUEGOS, el total de horas jugadas en c/u.\n",
    "dfResultadoU = dfResultadoU.dropna(subset=['genres'])        #Eliminanos los datos nan de la columna de fechas.\n",
    "\n",
    "dfResultadoU = dfResultadoU.groupby(['genres' , 'release_date'])['playtime_forever'].sum().reset_index()           # Agrupamos los datos por genero y año, sumando las horas.\n",
    "dfResultadoU['max'] = dfResultadoU.groupby('genres')['playtime_forever'].transform(max)           # Detectamos la mayor cantidad de horas y las agregamos a una columna auxiliar.\n",
    "dfResultadoU = dfResultadoU[dfResultadoU['playtime_forever'] == dfResultadoU['max']]         # Filtramos el dataframe para que traiga solo los generos y el año con la mayor cantidad de horas.\n",
    "dfResultadoU['release_date'] = dfResultadoU['release_date'].astype('int')         # Converimos el año a formato numerico.\n",
    "\n",
    "### EXPORTAMOS A .CSV EL DATAFRAME ###\n",
    "os.makedirs('Resultados', exist_ok = True)\n",
    "dfResultadoU.to_csv('Resultados/PConsulta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResultadoU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### SEGUNDA CONSULTA ###\n",
    "########################\n",
    "\n",
    "dfResultadoD = pd.merge(dfGames, dfReviews, how = 'inner', left_on='id', right_on='item_id')            # Creamos un nuevo dataframe, agrupando los juegos y las reviews.\n",
    "dfResultadoD = pd.merge(dfResultadoD, dfItems, how='inner', left_on=['user_id', 'item_id'], right_on=['user_id', 'item_id'])            # Agregamos al mismo dataframe, el tiempo juegado.\n",
    "dfResultadoD = dfResultadoD.drop(['tags', 'release_date',  'item_id', 'recommend', 'review', 'item_name'], axis = 1)          # Eliminamos las columnas que no seras utilizadas.\n",
    "\n",
    "for fila in dfResultadoD['posted']:\n",
    "    try:\n",
    "        dfResultadoD.loc[dfResultadoD['posted'] == fila, 'nueva_fecha'] = datetime.strptime(fila, 'Posted %B %d, %Y.').year         # Guardamos en una nueva columna, las fechas con formato valido (poseen anio).\n",
    "    except ValueError:\n",
    "       dfResultadoD.loc[dfResultadoD['posted'] == fila, 'nueva_fecha'] = None         # Si la fecha no es valida (no posee anio), guardamos un nan en su lugar.\n",
    "\n",
    "dfResultadoD = dfResultadoD.dropna(subset=['nueva_fecha'])        #Eliminanos los datos nan de la columna de fechas.\n",
    "dfResultadoD = dfResultadoD.groupby(['user_id', 'nueva_fecha', 'genres'])['playtime_forever'].sum().reset_index()           # Agrupamos los datos por usuario, anio y genero, sumando las horas.\n",
    "dfResultadoD['max'] = dfResultadoD.groupby(['user_id', 'genres'])['playtime_forever'].transform(sum)           # Sumamos las horas totales por genero de cada jugador y las agregamos a una columna auxiliar.\n",
    "dfResultadoD = dfResultadoD[dfResultadoD.groupby(\"genres\")[\"max\"].transform(max) == dfResultadoD[\"max\"]]            # Filtramos los datos por la maxima cantidad de horas, dejando solo los que necesitamos para la consulta.\n",
    "dfResultadoD['nueva_fecha'] = dfResultadoD['nueva_fecha'].astype('int')         # Converimos el año a formato numero.\n",
    "\n",
    "\n",
    "### EXPORTAMOS A .CSV EL DATAFRAME ###\n",
    "os.makedirs('Resultados', exist_ok = True)\n",
    "dfResultadoD.to_csv('Resultados/SConsulta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResultadoD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 3ra y 4ta CONSULTA ###\n",
    "##########################\n",
    "\n",
    "dfResultadoT = dfReviews\n",
    "\n",
    "for fila in dfResultadoT['posted']:\n",
    "    try:\n",
    "        dfResultadoT.loc[dfResultadoT['posted'] == fila, 'nueva_fecha'] = datetime.strptime(fila, 'Posted %B %d, %Y.').year         # Guardamos en una nueva columna, las fechas con formato valido (poseen anio).\n",
    "    except ValueError:\n",
    "       dfResultadoT.loc[dfResultadoT['posted'] == fila, 'nueva_fecha'] = None         # Si la fecha no es valida (no posee anio), guardamos un nan en su lugar.\n",
    "       \n",
    "dfResultadoT = dfResultadoT.dropna(subset=['nueva_fecha'])        #Eliminanos los datos nan de la columna de fechas.\n",
    "\n",
    "\n",
    "for fila in dfResultadoT['review']:\n",
    "    text_blob = TextBlob(fila)\n",
    "\n",
    "    polarity = text_blob.polarity           # Calculamos la polaridad de las reviews.\n",
    "    subjectivity = text_blob.subjectivity           # Calculamos la subjetividad de las rewiews.\n",
    "        \n",
    "    if subjectivity > 0.4:          # Si la subjetividad es mayor a 0.4, lo tomamos como una review valida [...] \n",
    "        if polarity > 0:\n",
    "            dfResultadoT.loc[dfResultadoT['review'] == fila, 'positi'] = 1          # Si la polaridad es mayor a cero, es positiva.\n",
    "        elif polarity < 0:\n",
    "            dfResultadoT.loc[dfResultadoT['review'] == fila, 'negati'] = 1          # Si la polaridad es menor a cero, es negativa.\n",
    "        else:\n",
    "            dfResultadoT.loc[dfResultadoT['review'] == fila, 'neutro'] = 1          # Si la polaridad es cero, es neutra.\n",
    "    else:\n",
    "        dfResultadoT.loc[dfResultadoT['review'] == fila, 'neutro'] = 1          # [...] De lo contrario lo marcamos como neutro.\n",
    "        \n",
    "dfResultadoT = dfResultadoT.groupby([\"recommend\", \"nueva_fecha\", \"item_id\"]).sum().reset_index()            # Agrupamos los datos por recomendacion, fecha e item. Sumamos los resultados del analisis.\n",
    "dfResultadoT = dfResultadoT.drop(['user_id', 'posted', 'review'], axis=1)         # Eliminamos la columnas que no utilizaremos.\n",
    "dfResultadoT['nueva_fecha'] = dfResultadoT['nueva_fecha'].astype('int')         # Convertimos los años a integer.\n",
    "dfResultadoT['neutro'] = dfResultadoT['neutro'].astype('int')         # Convertimos a integer.\n",
    "dfResultadoT['positi'] = dfResultadoT['positi'].astype('int')         # Convertimos a integer.\n",
    "dfResultadoT['negati'] = dfResultadoT['negati'].astype('int')         # Convertimos a integer.\n",
    "\n",
    "### EXPORTAMOS A .CSV EL DATAFRAME ###\n",
    "os.makedirs('Resultados', exist_ok=True)\n",
    "dfResultadoT.to_csv('Resultados/TConsulta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResultadoT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### QUINTA CONSULTA ###\n",
    "#######################\n",
    "\n",
    "dfResultadoQ = pd.merge(dfGames, dfResultadoT, how = 'inner', left_on='id', right_on = 'item_id')            # Creamos un nuevo dataframe, agregando a la consulta utilizada para el punto anterior la fecha de lanzamiento de los juegos.\n",
    "dfResultadoQ = dfResultadoQ.drop(['genres', 'item_id', 'app_name', 'tags', 'id', 'recommend', 'nueva_fecha'], axis = 1)           # Eliminamos columnas que no son necesarias.\n",
    "dfResultadoQ = dfResultadoQ.groupby('release_date').sum().reset_index()         # Agrupamos por año y sumamos los analisis.\n",
    "dfResultadoQ['release_date'] = dfResultadoQ['release_date'].astype('int')           # Convertimos los años en formato númerico.\n",
    "\n",
    "### EXPORTAMOS A .CSV EL DATAFRAME ###\n",
    "os.makedirs('Resultados', exist_ok = True)\n",
    "dfResultadoQ.to_csv('Resultados/QConsulta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResultadoQ.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
